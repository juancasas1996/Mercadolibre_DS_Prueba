{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════\n",
    "# 1. Librerías estándar y configuración general\n",
    "# ═══════════════════════════════════════════════\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# ═══════════════════════════════════════════════\n",
    "# 2. Preprocesamiento y ML clásico\n",
    "# ═══════════════════════════════════════════════\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "# ═══════════════════════════════════════════════\n",
    "# 3. Modelos\n",
    "# ═══════════════════════════════════════════════\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ═══════════════════════════════════════════════\n",
    "# 4. MLflow tracking\n",
    "# ═══════════════════════════════════════════════\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:../Experiments\")\n",
    "mlflow.set_experiment(\"LogisticRegression_Experiment\")\n",
    "run_name = \"LogReg_CV_Sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042c0c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets cargados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datasets preprocesados\n",
    "X_train = pd.read_csv(\"../Data/Gold/X_train_gold.csv\")\n",
    "X_test = pd.read_csv(\"../Data/Gold/X_test_gold.csv\")\n",
    "y_train = pd.read_csv(\"../Data/Gold/y_train_gold.csv\")\n",
    "y_test = pd.read_csv(\"../Data/Gold/y_test_gold.csv\")\n",
    "\n",
    "y_test.rename(columns={'0': 'condition'}, inplace=True)\n",
    "\n",
    "y_train_final = y_train[\"condition\"].map({\"used\": 0, \"new\": 1})\n",
    "y_test_final = y_test[\"condition\"].map({\"used\": 0, \"new\": 1})\n",
    "\n",
    "\n",
    "print(\"Datasets cargados correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e14ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END classifier__C=0.13292918943162169, classifier__solver=lbfgs; total time= 6.5min\n",
      "[CV] END classifier__C=0.13292918943162169, classifier__solver=lbfgs; total time= 6.9min\n",
      "[CV] END classifier__C=0.13292918943162169, classifier__solver=lbfgs; total time= 7.1min\n",
      "[CV] END classifier__C=0.13292918943162169, classifier__solver=lbfgs; total time= 7.1min\n",
      "[CV] END classifier__C=0.13292918943162169, classifier__solver=lbfgs; total time= 7.2min\n",
      "[CV] END classifier__C=0.6251373574521749, classifier__solver=lbfgs; total time=14.4min\n",
      "[CV] END classifier__C=0.21751953118777648, classifier__solver=lbfgs; total time= 9.6min\n",
      "[CV] END classifier__C=0.6251373574521749, classifier__solver=lbfgs; total time=13.3min\n",
      "[CV] END classifier__C=0.6251373574521749, classifier__solver=lbfgs; total time=14.0min\n",
      "[CV] END classifier__C=0.6251373574521749, classifier__solver=lbfgs; total time=13.9min\n",
      "[CV] END classifier__C=0.6251373574521749, classifier__solver=lbfgs; total time=14.3min\n",
      "[CV] END classifier__C=0.21751953118777648, classifier__solver=lbfgs; total time= 8.4min\n",
      "[CV] END classifier__C=0.035506214270707714, classifier__solver=saga; total time=23.4min\n",
      "[CV] END classifier__C=0.21751953118777648, classifier__solver=lbfgs; total time= 7.2min\n",
      "[CV] END classifier__C=0.21751953118777648, classifier__solver=lbfgs; total time= 5.2min\n",
      "[CV] END classifier__C=0.21751953118777648, classifier__solver=lbfgs; total time= 5.5min\n",
      "[CV] END classifier__C=0.035506214270707714, classifier__solver=saga; total time=28.3min\n",
      "[CV] END classifier__C=0.035506214270707714, classifier__solver=saga; total time=28.4min\n",
      "[CV] END classifier__C=0.035506214270707714, classifier__solver=saga; total time=28.5min\n",
      "[CV] END classifier__C=0.035506214270707714, classifier__solver=saga; total time=28.6min\n",
      "[CV] END classifier__C=0.014936568554617643, classifier__solver=saga; total time= 5.3min\n",
      "[CV] END classifier__C=0.014936568554617643, classifier__solver=saga; total time= 8.7min\n",
      "[CV] END classifier__C=0.014936568554617643, classifier__solver=saga; total time= 8.4min\n",
      "[CV] END classifier__C=0.014936568554617643, classifier__solver=saga; total time= 7.2min\n",
      "[CV] END classifier__C=0.014936568554617643, classifier__solver=saga; total time= 6.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/22 16:25:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logistic Regression Accuracy: 0.8488 | ROC AUC: 0.9209\n"
     ]
    }
   ],
   "source": [
    "# === Custom transformer\n",
    "class TopCityTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, city_col='seller_address.city.name', top_n=20):\n",
    "        self.city_col = city_col\n",
    "        self.top_n = top_n\n",
    "        self.top_cities_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.top_cities_ = X[self.city_col].value_counts().nlargest(self.top_n).index\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['city_grouped'] = X[self.city_col].apply(\n",
    "            lambda x: x if x in self.top_cities_ else 'other'\n",
    "        )\n",
    "        return X.drop(columns=['seller_id', self.city_col])\n",
    "\n",
    "\n",
    "# === Pipeline\n",
    "city_transformer = TopCityTransformer()\n",
    "\n",
    "# ColumnTransformer que selecciona columnas por tipo dinámicamente\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), selector(dtype_include=object)),\n",
    "    (\"num\", StandardScaler(), selector(dtype_include=np.number))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"city_transform\", city_transformer),\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# === Hiperparámetros\n",
    "param_dist = {\n",
    "    \"classifier__C\": loguniform(0.01, 10),\n",
    "    \"classifier__solver\": [\"lbfgs\", \"saga\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === Submuestreo (si aplica)\n",
    "X_sample = X_train.sample(frac=0.3, random_state=42)\n",
    "y_sample = y_train_final.loc[X_sample.index]\n",
    "\n",
    "# === MLflow + entrenamiento\n",
    "run_name = \"LogisticRegression_CV\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    search.fit(X_sample, y_sample)\n",
    "    best_pipeline = search.best_estimator_\n",
    "    mlflow.log_params(search.best_params_)\n",
    "\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "    y_prob = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test_final, y_pred)\n",
    "    auc = roc_auc_score(y_test_final, y_prob)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", auc)\n",
    "\n",
    "    mlflow.sklearn.log_model(best_pipeline, \"LogisticRegression_CV\")\n",
    "\n",
    "    print(f\"✅ Logistic Regression Accuracy: {acc:.4f} | ROC AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7525029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogisticRegression_CV\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39mrun_name):\n\u001b[0;32m---> 74\u001b[0m     search\u001b[38;5;241m.\u001b[39mfit(X_sample, y_sample)\n\u001b[1;32m     75\u001b[0m     best_pipeline \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     76\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_params(search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumz/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumz/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumz/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1961\u001b[0m         ParameterSampler(\n\u001b[1;32m   1962\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m   1963\u001b[0m         )\n\u001b[1;32m   1964\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumz/lib/python3.11/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    966\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m         clone(base_estimator),\n\u001b[1;32m    968\u001b[0m         X,\n\u001b[1;32m    969\u001b[0m         y,\n\u001b[1;32m    970\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    971\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    972\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    973\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    974\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m )\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumz/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumz/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumz/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumz/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# === Agrupar top ciudades\n",
    "top_cities = X_train['seller_address.city.name'].value_counts().nlargest(20).index\n",
    "X_train['city_grouped'] = X_train['seller_address.city.name'].apply(lambda x: x if x in top_cities else 'other')\n",
    "X_test['city_grouped'] = X_test['seller_address.city.name'].apply(lambda x: x if x in top_cities else 'other')\n",
    "\n",
    "# === Eliminar columnas de alta cardinalidad\n",
    "X_train_lr = X_train.drop(columns=['seller_id', 'seller_address.city.name'])\n",
    "X_test_lr = X_test.drop(columns=['seller_id', 'seller_address.city.name'])\n",
    "\n",
    "# === Submuestreo para evitar explosión de RAM\n",
    "X_sample = X_train_lr.sample(frac=0.3, random_state=42)\n",
    "y_sample = y_train_final.loc[X_sample.index]\n",
    "\n",
    "# === Columnas\n",
    "cat_cols = X_sample.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = X_sample.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# === Preprocesamiento\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "    (\"num\", StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "# === Pipeline base\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# === Búsqueda de hiperparámetros\n",
    "param_dist = {\n",
    "    \"classifier__C\": loguniform(0.01, 10),\n",
    "    \"classifier__solver\": [\"lbfgs\", \"saga\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    search.fit(X_sample, y_sample)\n",
    "\n",
    "    best_pipeline = search.best_estimator_\n",
    "    mlflow.log_params(search.best_params_)\n",
    "\n",
    "    # Evaluar en full test\n",
    "    y_pred = best_pipeline.predict(X_test_lr)\n",
    "    y_prob = best_pipeline.predict_proba(X_test_lr)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test_final, y_pred)\n",
    "    auc = roc_auc_score(y_test_final, y_prob)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", auc)\n",
    "    mlflow.sklearn.log_model(best_pipeline, \"LogisticRegression_CV\")\n",
    "\n",
    "    print(f\"✅ Logistic Regression Accuracy: {acc:.4f} | ROC AUC: {auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
