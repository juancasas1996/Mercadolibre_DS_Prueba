# ğŸ›’ Mercado Libre - ClasificaciÃ³n de Productos Nuevos vs Usados

Este proyecto busca predecir si un producto listado en Mercado Libre es **nuevo** o **usado**, implementando un pipeline completo de ciencia de datos: exploraciÃ³n, limpieza, ingenierÃ­a de variables, modelado, evaluaciÃ³n y despliegue.

---

## ğŸ“ 1. Dataset

El dataset contiene informaciÃ³n detallada de publicaciones, incluyendo:
- Descripciones y garantÃ­as
- MÃ©todos de pago
- Atributos y precios
- Fechas, ubicaciones y mÃ¡s

Muchos campos vienen anidados como **listas** o **diccionarios**, lo que motivÃ³ un procesamiento profundo.

---

## ğŸ” 2. ExploraciÃ³n y Limpieza (`01_EDA.ipynb`)

### ğŸ”¹ Columnas Complejas (listas/diccionarios)
- `descriptions`: Se extrajo `description_id`.
- `non_mercado_pago_payment_methods`: Se extrajo el mÃ©todo de pago principal. AgrupaciÃ³n de mÃ©todos relacionados con tarjetas bajo â€œTarjetaâ€.

### ğŸ”¹ Columnas tipo lista
Columnas como `sub_status`, `variations`, `deal_ids`, `attributes`, etc., fueron evaluadas segÃºn su % de vacÃ­os y su seÃ±al predictiva (`condition`). Resultado:
- Se eliminaron columnas con demasiados nulos o sin seÃ±al.
- Se crearon variables binarias como `has_variations`, `has_attributes`.

### ğŸ”¹ Columna `tags`
- 75.10% de filas contenÃ­an tags Ãºtiles.
- Se aplicÃ³ `MultiLabelBinarizer` + `OneHotEncoding`.

### ğŸ”¹ Valores nulos
- EstandarizaciÃ³n de `None`, `none`, `''` a `np.nan`.
- Se eliminaron columnas con mÃ¡s del 95% de nulos si no tenÃ­an valor predictivo.

### ğŸ”¹ Columnas constantes y casi constantes
- Se eliminaron columnas con un solo valor (ej: `site_id`, `thumbnail`, etc.).
- TambiÃ©n columnas con 95% del mismo valor.

### ğŸ”¹ Columna `warranty` (60% vacÃ­a)
- Se aplicÃ³ **NLP + Clustering**:
  - Embeddings con `sentence-transformers/all-MiniLM-L12-v2`.
  - Clustering con `KMeans(n_clusters=4)`.
  - Se creÃ³ una variable binaria: `has_warranty`.

### ğŸ”¹ Fechas y tiempos
- De `date_created`: se extrajeron `year`, `month`, `day`, `is_weekend`, etc.
- De `start_time` y `stop_time`: se generÃ³ `active_period`.

### ğŸ”¹ AgrupaciÃ³n y simplificaciÃ³n de categorÃ­as
- `currency_id` â†’ `Currency_ARS` (binaria)
- `status` â†’ agrupado como `active`, `paused`, `other`
- `shipping.mode` â†’ agrupaciÃ³n personalizada

### ğŸ”¹ Correlaciones fuertes
- `price` â‰ˆ `base_price` â†’ se eliminÃ³ uno
- `initial_quantity` â‰ˆ `available_quantity` â†’ se eliminÃ³ uno
- `seller_address.state.id` y `.name` eran equivalentes â†’ se eliminÃ³ uno

---

## ğŸ¤– 3. Modelos Entrenados

### ğŸ“˜ `03_Model_XGBoost.ipynb`
Entrenamiento de un modelo **XGBoost** con:
- CodificaciÃ³n mixta:
  - `OrdinalEncoder` para columnas de alta cardinalidad (`seller_id`, `city.name`, `category_id`)
  - `OneHotEncoder` para el resto de columnas categÃ³ricas
  - `StandardScaler` para numÃ©ricas
- BÃºsqueda con `RandomizedSearchCV`, 20 combinaciones probadas, validaciÃ³n con `StratifiedKFold`.
- Registro de mÃ©tricas (`accuracy`, `roc_auc`) y curva ROC en MLflow.
- Modelo registrado con `input_example` y `signature`.

---

### ğŸ“˜ `04_Model_Logistic.ipynb`
Entrenamiento de **regresiÃ³n logÃ­stica** con:
- Transformador personalizado `TopCityTransformer` para agrupar ciudades frecuentes.
- Pipeline con detecciÃ³n automÃ¡tica de columnas categÃ³ricas y numÃ©ricas (`make_column_selector`).
- Submuestreo del dataset para acelerar entrenamiento.
- OptimizaciÃ³n de hiperparÃ¡metros (`C`, `solver`) vÃ­a `RandomizedSearchCV`.
- Registro completo del modelo y mÃ©tricas en MLflow.

---

### ğŸ“˜ `05_Neural_Network.ipynb`
Entrenamiento de una **red neuronal simple (MLPClassifier)** con:
- AgrupaciÃ³n de ciudades (`city_grouped`) y eliminaciÃ³n de columnas de alta cardinalidad.
- Preprocesamiento tradicional con `OneHotEncoder` + `StandardScaler`.
- Arquitectura: `hidden_layer_sizes=(64,)`, `max_iter=200`.
- Registro directo del modelo sin tuning de hiperparÃ¡metros.

---

### ğŸ“˜ `06_Compare.ipynb`
- Recolecta todos los experimentos registrados en **MLflow**.
- Compara mÃ©tricas (`accuracy`, `roc_auc`) entre modelos.
- Carga cada modelo y genera su **matriz de confusiÃ³n** y `classification_report`.
- Selecciona automÃ¡ticamente el mejor modelo (segÃºn `accuracy`) y lo guarda como `best_model_production.pkl`.

---

### ğŸ“ˆ Resumen de resultados

| Modelo               | Accuracy | ROC AUC |
|----------------------|----------|---------|
| **XGBoost**          | 0.9021   | 0.9663  |
| Neural Network (MLP) | 0.8625   | 0.9358  |
| Logistic Regression  | 0.8467   | 0.9207  |

---

## ğŸ“Š 4. Tracking de Experimentos

Todos los modelos y sus ejecuciones fueron registrados con **MLflow**, incluyendo:
- HiperparÃ¡metros evaluados
- MÃ©tricas (`accuracy`, `roc_auc`)
- Artefactos como curvas ROC
- Modelos entrenados en cada run

El mejor modelo es seleccionado automÃ¡ticamente con base en su mÃ©trica.

---

## ğŸš€ 5. Despliegue con Streamlit

Una aplicaciÃ³n desarrollada con **Streamlit** permite:
- Subir archivos `.jsonlines` similares a `X_test` raw
- Procesar automÃ¡ticamente los datos y obtener predicciones
- Descargar los resultados en `.csv`
- Acceso protegido con contraseÃ±a: `Meli`

---

## ğŸ—‚ï¸ 6. Estructura del Proyecto

<pre lang="markdown"><code>

MercadoLibre_Test/
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ gold/
â”‚
â”œâ”€â”€ Notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb
â”‚   â”œâ”€â”€ 02_Data_Preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_Model_XGBoost.ipynb
â”‚   â”œâ”€â”€ 04_Model_Logistic.ipynb
â”‚   â”œâ”€â”€ 05_Neural_Network.ipynb
â”‚   â”œâ”€â”€ 06_Compare.ipynb
â”‚
â”œâ”€â”€ Models/
â”‚   â””â”€â”€ best_model_production.pkl
â”‚
â”œâ”€â”€ Experiments/
â”‚   â””â”€â”€ (MLflow tracking runs)
â”‚
â”œâ”€â”€ App/
â”‚   â”œâ”€â”€ streamlit.py
â”‚   â”œâ”€â”€ Data_Processing.py
â”‚   â”œâ”€â”€ Register_Best_Model.py
â”‚
â”œâ”€â”€ Artefacts/
â”‚   â””â”€â”€ preprocessors/
â”‚       â”œâ”€â”€ kmeans_warranty.pkl
â”‚       â”œâ”€â”€ mlb_tags.pkl
â”‚       â”œâ”€â”€ warranty_cluster_map.pkl
â”‚
â””â”€â”€ Docker/ (En desarrollo)
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ app.py
    â””â”€â”€ requirements.txt

</code></pre>

---

## â³ 7. Pendientes

- Finalizar el contenedor Docker para facilitar el despliegue reproducible.
- Optimizar el entrenamiento de modelos mÃ¡s pesados si se dispone de mayor capacidad computacional.

---

## âš™ï¸ 8. Requisitos

- Python 3.11+
- `scikit-learn`, `xgboost`, `streamlit`, `mlflow`, `sentence-transformers`, `pandas`, `matplotlib`, `joblib`

InstalaciÃ³n rÃ¡pida:

```bash
pip install -r Docker/requirements.txt