# ğŸ›’ Mercado Libre - ClasificaciÃ³n de Productos Nuevos vs Usados

Este proyecto busca predecir si un producto listado en Mercado Libre es **nuevo** o **usado**, implementando un pipeline completo de ciencia de datos: exploraciÃ³n, limpieza, ingenierÃ­a de variables, modelado, evaluaciÃ³n y despliegue.

---

## ğŸ“ 1. Dataset

El dataset contiene informaciÃ³n detallada de publicaciones, incluyendo:
- Descripciones y garantÃ­as
- MÃ©todos de pago
- Atributos y precios
- Fechas, ubicaciones y mÃ¡s

Muchos campos vienen anidados como **listas** o **diccionarios**, lo que motivÃ³ un procesamiento profundo.

---

## ğŸ” 2. ExploraciÃ³n y Limpieza (`01_EDA.ipynb`)

### ğŸ”¹ Columnas Complejas (listas/diccionarios)
- `descriptions`: Se extrajo `description_id`.
- `non_mercado_pago_payment_methods`: Se extrajo el mÃ©todo de pago principal. AgrupaciÃ³n de mÃ©todos relacionados con tarjetas bajo â€œTarjetaâ€.

### ğŸ”¹ Columnas tipo lista
Columnas como `sub_status`, `variations`, `deal_ids`, `attributes`, etc., fueron evaluadas segÃºn su % de vacÃ­os y su seÃ±al predictiva (`condition`). Resultado:
- Se eliminaron columnas con demasiados nulos o sin seÃ±al.
- Se crearon variables binarias como `has_variations`, `has_attributes`.

### ğŸ”¹ Columna `tags`
- 75.10% de filas contenÃ­an tags Ãºtiles.
- Se aplicÃ³ `MultiLabelBinarizer` + `OneHotEncoding`.

### ğŸ”¹ Valores nulos
- EstandarizaciÃ³n de `None`, `none`, `''` a `np.nan`.
- Se eliminaron columnas con mÃ¡s del 95% de nulos si no tenÃ­an valor predictivo.

### ğŸ”¹ Columnas constantes y casi constantes
- Se eliminaron columnas con un solo valor (ej: `site_id`, `thumbnail`, etc.).
- TambiÃ©n columnas con 95% del mismo valor.

### ğŸ”¹ Columna `warranty` (60% vacÃ­a)
- Se aplicÃ³ **NLP + Clustering**:
  - Embeddings con `sentence-transformers/all-MiniLM-L12-v2`.
  - Clustering con `KMeans(n_clusters=4)`.
  - Se creÃ³ una variable binaria: `has_warranty`.

### ğŸ”¹ Fechas y tiempos
- De `date_created`: se extrajeron `year`, `month`, `day`, `is_weekend`, etc.
- De `start_time` y `stop_time`: se generÃ³ `active_period`.

### ğŸ”¹ AgrupaciÃ³n y simplificaciÃ³n de categorÃ­as
- `currency_id` â†’ `Currency_ARS` (binaria)
- `status` â†’ agrupado como `active`, `paused`, `other`
- `shipping.mode` â†’ agrupaciÃ³n personalizada

### ğŸ”¹ Correlaciones fuertes
- `price` â‰ˆ `base_price` â†’ se eliminÃ³ uno
- `initial_quantity` â‰ˆ `available_quantity` â†’ se eliminÃ³ uno
- `seller_address.state.id` y `.name` eran equivalentes â†’ se eliminÃ³ uno

---

## ğŸ¤– 3. Modelos Entrenados

| Modelo               | Accuracy | ROC AUC |
|----------------------|----------|---------|
| **XGBoost**          | 0.9021   | 0.9663  |
| Logistic Regression  | 0.8467   | 0.9207  |
| Neural Network (MLP) | 0.8625   | 0.9358  |

### Detalles:
- **XGBoost**: RandomizedSearchCV con codificaciÃ³n mixta (`OneHotEncoder` y `OrdinalEncoder`)
- **Logistic Regression**: Submuestreo + GridSearch
- **Neural Network**: ReducciÃ³n del dataset por limitaciones de memoria

---

## ğŸ“Š 4. Tracking de Experimentos

Todos los experimentos fueron registrados en **MLflow**, incluyendo:
- HiperparÃ¡metros
- MÃ©tricas (accuracy, ROC AUC)
- Curvas ROC
- Modelos entrenados

El mejor modelo fue seleccionado automÃ¡ticamente por mÃ©trica.

---

## ğŸš€ 5. Despliegue con Streamlit

Una aplicaciÃ³n simple desarrollada con **Streamlit** permite:
- Subir un archivo CSV similar a `X_test` raw
- Obtener predicciones y descargar el archivo con resultados
- Acceso protegido con contraseÃ±a: `Meli`

---

## ğŸ—‚ï¸ 6. Estructura del Proyecto


<pre lang="markdown"><code>
```text
MercadoLibre_Test/
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ gold/
â”‚
â”œâ”€â”€ Notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb
â”‚   â”œâ”€â”€ 02_Data_Preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_Model_XGBoost.ipynb
â”‚   â”œâ”€â”€ 04_Model_Logistic.ipynb
â”‚   â”œâ”€â”€ 05_Neural_Network.ipynb
â”‚   â”œâ”€â”€ 06_Compare.ipynb
â”‚
â”œâ”€â”€ Models/
â”‚   â””â”€â”€ best_model_production.pkl
â”‚
â”œâ”€â”€ Experiments/
â”‚   â””â”€â”€ (MLflow tracking runs)
â”‚
â”œâ”€â”€ App/
â”‚   â”œâ”€â”€ streamlit.py
â”‚   â”œâ”€â”€ Data_Processing.py
â”‚   â”œâ”€â”€ Register_Best_Model.py
â”‚
â”œâ”€â”€ Artefacts/
â”‚   â””â”€â”€ preprocessors/
â”‚       â”œâ”€â”€ kmeans_warranty.pkl
â”‚       â”œâ”€â”€ mlb_tags.pkl
â”‚       â”œâ”€â”€ warranty_cluster_map.pkl
â”‚
â””â”€â”€ Docker/ (En desarrollo)
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ app.py
    â””â”€â”€ requirements.txt
```
</code></pre>



## ğŸ§  7. JustificaciÃ³n de la mÃ©trica ROC AUC

Se eligiÃ³ **ROC AUC** como mÃ©trica principal junto a Accuracy porque:
- Proporciona una visiÃ³n balanceada del desempeÃ±o ante clases desbalanceadas.
- EvalÃºa la capacidad del modelo para rankear correctamente observaciones.
- Es robusta ante cambios de umbral de decisiÃ³n.

---

## â³ 8. Pendientes

- Finalizar el contenedor Docker para facilitar el despliegue reproducible.
- Optimizar entrenamiento de modelos mÃ¡s pesados si se dispone de mayor capacidad.

---

## âš™ï¸ 9. Requisitos

- Python 3.11+
- `scikit-learn`, `xgboost`, `streamlit`, `mlflow`, `sentence-transformers`, `pandas`, `matplotlib`, `joblib`

InstalaciÃ³n rÃ¡pida:

```bash
pip install -r Docker/requirements.txt